
â”‚   â”œâ”€â”€ make_dataset.py     # prepare processed dataset
â”‚   â”œâ”€â”€ train.py            # train + save best model
â”‚   â”œâ”€â”€ evaluate.py         # metrics + confusion matrix plot
â”‚   â””â”€â”€ predict.py          # CLI inference from raw text
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.joblib
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ metrics.json
â”‚   â”œâ”€â”€ classification_report.txt
â”‚   â””â”€â”€ figures/
â”‚       â””â”€â”€ confusion_matrix.png
â”‚       â””â”€â”€model_accuracy.png
â”œâ”€â”€ notebooks/
â””â”€â”€ requirements.txt

````

---

## âš™ï¸ Setup
Install dependencies:

```bash
pip install -r requirements.txt
````

---

## ğŸš€ How to Run (End-to-End)

### 1ï¸âƒ£ Build processed dataset

Creates: `data/processed/dataset.csv`

```bash
python -m src.make_dataset
```

### 2ï¸âƒ£ Train model

Creates: `models/model.joblib`

```bash
python -m src.train
```

### 3ï¸âƒ£ Evaluate model + generate plots

Creates:

* `reports/metrics.json`
* `reports/classification_report.txt`
* `reports/figures/confusion_matrix.png`

```bash
python -m src.evaluate
```

---

## ğŸ“ˆ Metrics

Metrics are stored in:

* `reports/metrics.json`

Recommended metrics for multi-class text classification:

